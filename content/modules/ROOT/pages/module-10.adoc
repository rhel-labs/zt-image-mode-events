= Repurposing a bootc host

In addition to simplifying updates and providing native rollback, operating RHEL in image mode also makes it simple to quickly change the purpose of a running system.

The `switch` operation allows adminstrators to change the system software to a different image, while keeping local system configuration and data intact.

In this lab we'll explore this feature as well as expand on the idea of standardized builds and derived images.

[#write-containerfiles]
== Testing the developers bug report

While testing their proof of concept, the developers found that the image they created worked fine when a machine was newly installed.
To help save time, they wanted to repurpose a few other image mode machines instead of requesting brand new infrastructure.
When they switched the running machine, the application wouldn't start.
They only had a RHEL 9.6 host to test, and they weren't sure if moving to RHEL 10.1 was part of the problem.

Change to th git repository for the application with the bootc Containerfile, cloned onto the build host.
[source,bash,role="execute",subs=attributes+]
----
cd ~/bootc-version
----

First, let's add linting and then build a fresh copy to test the switch on our own RHEL 9.6 host.
[source,bash,role="execute",subs=attributes+]
----
nano Containerfile
----

Add the following line as the last instruction in the Containerfile.
We always want linting to be the final step in a build.
[source,dockerfile,role="execute",subs=attributes+]
----
RUN bootc container lint
----

The linter is designed to issue warnings about potential problems and will error and stop the build if there is something that would stop an image mode host from operating. 
Some warnings are harmless, but others could point to issues with certain types of operations during the lifetime of a host.

== Build and push the image

When we build this image, we will use a new name to denote its new purpose. Your naming and tagging conventions should aim to convey information to the people who need them as much as providing hooks to automate and control visibility to hosts.

[source,bash,role="execute",subs=attributes+]
----
podman build --file Containerfile --tag registry-{guid}.{domain}/app-test
----
no errors, but we do see warnings about content in `/var` about logs, directories, and other files. 
....
STEP 15/15: RUN bootc container lint
Lint warning: var-log: Found non-empty logfiles:
  /var/log/dnf.librepo.log
  /var/log/dnf.log
  /var/log/dnf.rpm.log
  /var/log/hawkey.log
  /var/log/rhsm/rhsm.log

Lint warning: var-tmpfiles: Found content in /var missing systemd tmpfiles.d entries:
  d /var/lib/dnf 0755 root root - -
  d /var/lib/nginx 0770 nginx root - -
  d /var/lib/nginx/tmp 0770 nginx root - -
  d /var/log/nginx 0711 root root - -
  d /var/roothome/.cache 0755 root root - -
  ...and 128 more
Found non-directory/non-symlink files in /var:
  var/lib/dnf/history.sqlite
  var/lib/dnf/history.sqlite-shm
  var/lib/dnf/history.sqlite-wal
  var/lib/rhsm/cache/productid_repo_mapping.json
  var/lib/rhsm/productid.js
  ...and 66 more
....

There's quite a few warnings, so our culprit may be in there. 
[#build]

Push this image to the registry so we can use it to test on our existing target host.
[source,bash,role="execute",subs=attributes+]
----
podman push registry-{guid}.{domain}/app-test
----


[#switch-run]
== Switch and test the image

Change to the tab labeled "Test image mode host".

You saw earlier how `bootc` tracks the image in the registry to find updates.
To change to a different image, use the `bootc switch` command to provide a different image specification.
We'll use it to change into the testing image we just pushed to the registry.
[source,bash,role="execute",subs=attributes+]
----
bootc switch registry-{guid}.{domain}/app-test
----
NOTE: You may see warnings about Non-ASCII characters, this is a side effect of moving a RHEL 9 host to RHEL 10, and doesn't affect the host.

From an output perspective, a switch looks the same as an update. There's a new deployment that's been staged and prepared for the next boot, but the image reference is completely different.

[source,bash,role="execute",subs=attributes+]
----
bootc status 
----
....
  Staged image: registry-bcsvm.apps.ocpvdev01.rhdp.net/app-test
        Digest: sha256:7bf214162491f10288150824d14cafbd7da62336255c9f043ffd1ebeec1ad3d2
       Version: 10.1 (2025-11-17 16:03:11.935540475 UTC)

● Booted image: quay.io/mmicene/im-day2-tgt:9.6
        Digest: sha256:b8b171136d276dc943a27fcdc6b90876538fffef502622109e1451492a9c7de7
       Version: 9.6 (2025-09-08 18:56:51.120175635 UTC)
....

Issue a full reboot to finalize the switch, making sure you're on the right host.

[source,bash,role="execute",subs=attributes+]
----
systemctl reboot
----

After a short while, you can log back in to the virtual machine by clicking `reconnect` or using the refresh button in the tab.

[#layers]
== Troubleshooting derived builds

You should see the failed nginx unit on login, so check the status output of the service to see what happened.
....
[systemd]
Failed Units: 1
  nginx.services
....
[source,bash,role="execute",subs=attributes+]
----
systemctl status nginx.service --no-pager
----
....
Nov 17 16:18:10 imrhel systemd[1]: Starting nginx.service - The nginx HTTP and reverse proxy server...
Nov 17 16:18:10 imrhel nginx[1078]: nginx: [alert] could not open error log file: open() "/var/log/nginx/error.log…irectory)
Nov 17 16:18:10 imrhel nginx[1078]: nginx: the configuration file /etc/nginx/nginx.conf syntax is ok
Nov 17 16:18:10 imrhel nginx[1078]: 2025/11/17 16:18:10 [emerg] 1078#1078: mkdir() "/var/lib/nginx/tmp/client_body…irectory)
Nov 17 16:18:10 imrhel nginx[1078]: nginx: configuration file /etc/nginx/nginx.conf test failed
....

Looks the culprit is nginx missing its `/var` file structure but why does that not happen when the developers provision a new machine?

In an image mode system, `bootc` handles the following directories differently, which is what allows for the seamless update and rollback experience. 

  * `/usr` -> image state, contents of the image will be extracted and overwrite local files
  * `/etc` -> local configuration state, contents of the image are merged with a preference for local files
  * `/var` -> local state, contents of the image will be ignored after the initial installation of any image

At install, initial nginx logs and workfing files created during the build went in `/var` which means after it was unpacked from the original image, `bootc` treated it as local machine state. 
So the directories created by the RPM aren't created on the running host, which explains why a fresh install launches the app but a switch fails. 
This is one of the new mental models that needs to be adopted to handle image mode operations. 

If `/var` is hands-off after initial provisioning, how can you account for common directories that need to be present in `/var` on all systems?
By using `systemd tmpfiles` to manage them at boot.

We don't expect you to handle all of these cases manually. 
Upstream packages have been moving to use `systemd tmpfiles` and `systemd sysusers` to handle user and file creation for some time.
The introduction of image mode has put some pressure on this migration, but you can already see the `nginx` package https://src.fedoraproject.org/rpms/nginx/blob/aff374fc9038f31a53370f5779f4d03df8fbbc6d/f/nginx.tmpfiles[already has a fix upstream.]

== Workaround rebuild

Let's use the upstream fix to create a local version of nginx.tmpfiles in the system location. 
This means when the new RPM lands, we can just remove this from our Containerfile and the system will continue to work as expected.

Switch to the tab labeled Build host.

Let's add a `heredoc` just before the linter in the Containerfile to create the new file for testing.
[source,bash,role="execute",subs=attributes+]
----
nano Containerfile
----
[source,dockerfile,role="execute",subs=attributes+]
----
RUN <<EORUN
    set -exuo pipefail
    echo "d /var/lib/nginx     770 nginx root -" >> /usr/lib/tmpfiles.d/nginx.conf
    echo "d /var/lib/nginx/tmp 770 nginx root -" >> /usr/lib/tmpfiles.d/nginx.conf
    echo "d /var/log/nginx     711 root  root -" >> /usr/lib/tmpfiles.d/nginx.conf
EORUN
----

Using the `heredoc` let's us run multiple commands as a single layer and can be very handy.
Since this is executed during a build like any other shell `heredoc`, we need to use some `set` magic to make sure a failure here stops the build.

To test that `systemd` will handle the directory creation on a switch and let the app now start, we'll build this image with a new tag.

TIP: Another option would be to rollback the target host and reuse the same default `latest` tag. The outcome on the switch executed on the host would be the same.

[source,bash,role="execute",subs=attributes+]
----
podman build --file Containerfile --tag registry-{guid}.{domain}/app-test:v2
----
Note the linter isn't complaining about `nginx` in `/var` any more.
....
Lint warning: var-tmpfiles: Found content in /var missing systemd tmpfiles.d entries:
  d /var/lib/dnf 0755 root root - -
  d /var/roothome/.cache 0755 root root - -
  d /var/roothome/.cache/pip 0755 root root - -
  d /var/roothome/.cache/pip/http-v2 0755 root root - -
  d /var/roothome/.cache/pip/http-v2/0 0755 root root - -
....
And of course push it to the local registry:

[source,bash,role="execute",subs=attributes+]
----
podman push registry-{guid}.{domain}/app-test:v2
----

=== Testing the workaround
Change to the tab labeled "Test image mode host".

Let's use the `--apply` flag and immediately execute the reboot instead of checking the status first.
[source,bash,role="execute",subs=attributes+]
----
bootc switch registry-{guid}.{domain}/app-test:v2 --apply
----

After a short while, you can log back in to the virtual machine by clicking `reconnect` or using the refresh button in the tab.
There's no systemd warning on login, so check the status of nginx and the application.
[source,bash,role="execute",subs=attributes+]
----
systemctl status nginx.service --no-pager
----
....
Nov 17 17:03:33 imrhel systemd[1]: Starting nginx.service - The nginx HTTP and reverse proxy server...
Nov 17 17:03:34 imrhel nginx[1055]: nginx: the configuration file /etc/nginx/nginx.conf syntax is ok
Nov 17 17:03:34 imrhel nginx[1055]: nginx: configuration file /etc/nginx/nginx.conf test is successful
Nov 17 17:03:34 imrhel systemd[1]: Started nginx.service - The nginx HTTP and reverse proxy server.
....

[source,bash,role="execute",subs=attributes+]
----
systemctl status info-app.service --no-pager
----
....
Nov 17 17:03:49 localhost.localdomain systemd[1]: Started info-app.service - Host information services.
Nov 17 17:03:49 imrhel gunicorn[958]: [2025-11-26 23:09:49 +0000] [958] [INFO] Starting gunicorn 23.0.0
Nov 17 17:03:49 imrhel gunicorn[958]: [2025-11-26 23:09:49 +0000] [958] [INFO] Listening at: unix:/…k (958)
Nov 17 17:03:49 imrhel gunicorn[958]: [2025-11-26 23:09:49 +0000] [958] [INFO] Using worker: sync
....
As a final sanity check, is the app http://app-{guid}.{domain}/[up and running?,window=_blank]

The host details page is up and running on the test host. With that solved, we can start on migrating the app from the Red Hat base to our corporate baseline.


== Core principles
Easy updates, rollbacks, and image switching are part of the core improvements to the operation of image mode systems. 
Knowing how changes to the filesystem are managed by `bootc` is important to navigating the differences between image mode and package mode.

Layering is an important part of the design of standard builds and can have some downstream effects as well. 
Just like stacking configuration management, thinking through the idea of layered builds can be powerful.
In the next exercises, we'll dig deeper into derived builds for the application.
