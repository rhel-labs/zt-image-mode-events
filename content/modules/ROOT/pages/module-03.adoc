= Deploy a virtual machine from a bootc image

In this exercise, you will build a `qcow2` disk image from the bootc image and then launch
a virtual machine from it. `qcow2` is a standard file format used by the Linux virtualization system.

[#config]
== Create the config for building the virtual machine image

To deploy our bootc image as a host, we need to get the contents of the image onto a disk. While `bootc` handles those mechanics, the actual creation of a physical disk, virtual disk, or cloud image are handled by other standard tools.
For example, Anaconda can be used with bootc images for physical or virtual hosts like you would today. 

In this lab, we'll use the `bootc-image-builder` tool which can create various different disk image types and call `bootc` to deploy the image contents. This is a variant of the Image Builder tooling you are already familiar with, just containerized and with `bootc` built in.

You may have noticed the bootc image we've created does not include any login credentials. 
Not a typical concern for an application container, but as a host we will very likely need to interact with it at some point. 
Since we are defining an image to be shared by multiple hosts in multiple different environments, users and authentication is most likely to be handled at the *deployment* stage, not the build stage.

TIP: There are cases where it may be useful for a user and credentials to be added to an image, 
as a 'break glass' emergency login for example.

To add a user during the deployment to a disk image, the credentials are put into the config file used by `bootc-image-builder` to create the final disk image.

You can now create a file called `config.toml` with the following contents to create a user with the specified values.

You'll be replacing "SSHKEY" placeholder in the `key` field with the contents of public key from your system in the next step.

[source,bash,role="execute",subs=attributes+]
----
nano config.toml
----

[source,yaml,role="execute",subs=attributes+]
----
[[customizations.user]]
name = "core"
password = "redhat"
groups = ["wheel"]
key = "SSHKEY"
----

This configuration blueprint creates a user in the wheel group with the login `core`, the password `redhat` and the ssh key of the user on the lab host.

Save the file and return to the terminal to get the ssh key.
An ssh key pair was generated for use during this lab, you can copy the key and edit the `config.toml` to replace the `SSHKEY` with the actual key.
_There's no newline at the end of this file, so the `echo` is just to make copying the output easier._

[source,bash,role="execute",subs=attributes+]
----
cat ~/.ssh/{guid}key.pub; echo
----
....
ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIAuXnpoluye+KM+9tvIAdHf+F0IHh+K73tlcjEG8LJRB
....
NOTE: This is only a sample and this public key will not work in your environment

[#create]
== Create the disk image

To create a bootable disk image from an OCI image, we have a special version of image builder that has support for `bootc`. This `bootc-image-builder` itself runs as a container, and as a result needs additional capabilities and to be run as `root`. 

As `bootc-image-builder` accesses local storage to find the source image, we need our image in system storage. 
If we'd built as a non-root user, the `podman image scp` command can do this for us, as well as copying to various different targets.


Try to generate the image now:

NOTE: This could take 2+ minutes to complete.

[source,bash,role="execute",subs=attributes+]
----
podman run --rm --privileged --security-opt label=type:unconfined_t \
  --volume ./config.toml:/config.toml \
  --volume /var/lib/containers/storage:/var/lib/containers/storage \
  --volume .:/output \
  registry.redhat.io/rhel10/bootc-image-builder:10.1 \
  --type qcow2 \
  registry-{guid}.{domain}/base
----

A brief explanation of the arguments used for `podman run` and `bootc-image-builder`:

  * `--privileged` -> add capabilities required to build the image
  * `--volume` -> podman will map these local directories or files to the container to capture the config, load the bootc image, and store the results
  * `registry.redhat.io/rhel10/bootc-image-builder:10.1` -> the image builder container image

After the image builder version, these arguments passed to `bootc-image-builder`:

  * `--type qcow2` -> the type of image to build
  * `registry-{guid}.{domain}/base` -> the bootc image we are unpacking into the qcow2 disk

Once this completes, you will find the image in the `qcow2/` directory:

[source,bash,role="execute",subs=attributes+]
----
file qcow2/disk.qcow2
----
....
qcow2/disk.qcow2: QEMU QCOW2 Image (v3), 10737418240 bytes
....

[#create-vm]
== Create the virtual machine

Since we provided the QCOW2 type to `bootc-image-builder`, the resulting disk image is complete and ready to run without additional installation or other steps. We can copy the image to the standard storage pool location for KVM.

[source,bash,role="execute",subs=attributes+]
----
cp qcow2/disk.qcow2 /var/lib/libvirt/images/bootc-vm.qcow2
----

The creation of KVM virtual machines is out of scope for this lab, but the core of the `virt-install` command used is `--import` which skips any install process and creates the VM around the provided disk image. 

[source,bash,role="execute",subs=attributes+]
----
virt-install --name bootc-vm \
  --disk /var/lib/libvirt/images/bootc-vm.qcow2 \
  --import \
  --memory 4096 \
  --graphics none \
  --osinfo rhel10-unknown \
  --noautoconsole \
  --noreboot
----

We can now start our new bootc virtual machine.

[source,bash,role="execute",subs=attributes+]
----
virsh start bootc-vm
----

== Swith to the image mode VM
NOTE: The terminal pages for the KVM guests have a script that will wait for SSH to become available before trying to log in. If there's a problem with an SSH connection, you can restart the connection using the refresh button in the tab.

[#test]
== Test and login to the virtual machine
_Click on the tab labeled "Intial VM"_ 

Once the script detects SSH is running, you should be automatically logged in as the `core` user created in the `bootc-image-builder` customization. 
....
[core@localhost ~]$
....

Let's test one of the packages installed from `EPEL` during the build process.
[source,bash,role="execute",subs=attributes+]
----
btop
----
TIP: You can hit `q` to exit `btop`

Image mode hosts introduce a new way of understanding what's running on a host. 
The new `bootc` command is at the heart of operations on image mode hosts.
Let's familiarize ourselves with the `status` options first.

This status provides information about the images on the host. There are 3 different images that may be available on a bootc host: the booted image, the staged image, and the rollback image. We'll discuss the latter two images later in the lab. The booted image is what's currently defined as the active environment. The image name here is what `bootc` tracks to detect any updates that come available. 

TIP: The user password was also defined in the `config.toml` as *redhat*

[source,bash,role="execute",subs=attributes+]
----
sudo bootc status
----
....
Booted image: registry-pw6dg.apps.ocpvdev01.rhdp.net/base
        Digest: sha256:3d0fab2f019f5b641ccf3e41853f2e3b720a96aaa7a3d786548a47b3f098cc02 (amd64)
       Version: 10.1 (2025-11-19T17:11:53Z)
....

First, `bootc` tells you directly if it's being run on an image mode host or not. If `bootc` were to be installed and run on a non-bootc host, `bootc status` will show all `null` values instead of the output seen here. 
The core information shows is the image in use, the digest, and some version information.

More information is available with the `--verbose` flag.
[source,bash,role="execute",subs=attributes+]
----
sudo bootc status --verbose
----
....
Booted image: registry-pw6dg.apps.ocpvdev01.rhdp.net/base
        Digest: sha256:3d0fab2f019f5b641ccf3e41853f2e3b720a96aaa7a3d786548a47b3f098cc02 (amd64)
       Version: 10.1 (2025-11-19T17:11:53Z)
     StateRoot: default
 Deploy serial: 0
        Staged: no
        Commit: 564872a699359b7988e63851bc24b60da83072c0c150849c4ecd8f606c0aa487
   Soft-reboot: yes
....
You can see the details of image in use, but also some `bootc` internals that show operational information about the booted image.

Status doesn't stop there.
Full internal information about the images can be found by using the `--format` tag to ask for additional detail in YAML or JSON.
This can be useful for troubleshooting or for using this information in other tools.
[source,bash,role="execute",subs=attributes+]
----
sudo bootc status --format yaml
----
....
apiVersion: org.containers.bootc/v1
kind: BootcHost
metadata:
  name: host
spec:
  image:
    image: registry-q4j7p.apps.ocpvdev01.rhdp.net/base
    transport: registry
  bootOrder: default
status:
  staged: null
  booted:
    image:
      image:
        image: registry-q4j7p.apps.ocpvdev01.rhdp.net/base
        transport: registry
      version: '10.1'
      timestamp: 2025-12-09T06:23:07Z
      imageDigest: sha256:730892a19b22daca7be394ede0543979573334cfdffd43cb77a860852cf788fc
      architecture: amd64
    cachedUpdate: null
    incompatible: false
    pinned: false
    softRebootCapable: true
    store: ostreeContainer
    ostree:
      stateroot: default
      checksum: 7794ee898bcb76da5a18e5c0ffb18504f6e402aa1df7cde9dff50164dca78c1c
      deploySerial: 0
  rollback: null
  rollbackQueued: false
  type: BootcHost
....

Not only do we get detailed information, it's categorized a little differently.
You can see where fields from the `--verbose` flag line up against internal structures like image information versus ostree internals. 

For other ways, we can look at how the system was started, let's look at kernel command line.

[source,bash,role="execute",subs=attributes+]
----
 cat /proc/cmdline
----
....
BOOT_IMAGE=(hd0,gpt3)/boot/ostree/default-9cba41d43c6b3669ffb845fb0fc12443e5f9e5858364353132fb68999df2c85e/vmlinuz-6.12.0-124.20.1.el10_1.x86_64 root=UUID=e89f7d46-c45d-4c22-aebc-9e6a9d037171 rw boot=UUID=dec2cfec-b437-490a-bf10-34de519b96e6 rw console=tty0 console=ttyS0 ostree=/ostree/boot.1/default/9cba41d43c6b3669ffb845fb0fc12443e5f9e5858364353132fb68999df2c85e/0
....

We can see in the kernel command line some clear ties to an `ostree` partition, which is how images are stored and managed on a bootc host. We'll talk more about that later.

One other obvious difference for bootc hosts is the layout of the filesystem. 

[source,bash,role="execute",subs=attributes+]
----
df -Th | grep -v /run
----
....
Filesystem     Type      Size  Used Avail Use% Mounted on
composefs      overlay   7.7M  7.7M     0 100% /
/dev/vda4      xfs       8.5G  2.3G  6.3G  27% /etc
devtmpfs       devtmpfs  1.9G     0  1.9G   0% /dev
tmpfs          tmpfs     2.0G     0  2.0G   0% /dev/shm
tmpfs          tmpfs     2.0G     0  2.0G   0% /tmp
/dev/vda3      xfs       960M  157M  804M  17% /boot
/dev/vda2      vfat      501M  8.8M  492M   2% /boot/efi
....

Skipping the runtime system directories, rather than the usual layout, you'll notice that our root filesystem is an overlay and `/sysroot` looks like where most of the storage is used. 
You can also check the output of `ls -l /` and notice that there are a lot of symlinks where you might expect directories or filesystems.  i
This is a key difference that is tied to how updates, rollbacks, and software management works on image mode hosts.  We'll explore this in a later exercise.

_Before proceeding, make sure you have changed back to the tab labeled "Build host'._

