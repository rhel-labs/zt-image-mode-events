= Deploy a virtual machine from a bootc image

In this exercise, you will build a `qcow2` disk image from the bootc image and then launch
a virtual machine from it. `qcow2` is a standard file format used by the Linux virtualization system.

[#config]
== Create the config for building the virtual machine image

To deploy our bootc image as a host, we need to get the contents of the image onto a disk. While `bootc` 
handles those mechanics, the actual creation of a physical disk, virtual disk, or cloud image are handled 
by other standard tools. For example, Anaconda can be used with bootc images for physical or virtual hosts 
like you would today. 

In this lab, we'll use the `bootc-image-builder` tool which can create various different disk image types and call `bootc` to deploy the image contents. This is a variant of the Image Builder tooling you are already familiar with, just containerized and with `bootc` built in.

You may have noticed the bootc image we've created does not include any login credentials. Not a 
typical concern for an application container, but as a host we will very likely need to interact
at some point. Since we are defining an image to be shared by multiple hosts in multiple different environments,
users and authentication is likely to be handled at the deployment stage, not the build stage.

TIP: There are cases where it may be useful for a user and credentials to be added to an image, 
as a 'break glass' emergency login for example.

To add a user during the deployment to a disk image, the credentials are put into the config file used by `bootc-image-builder` to create the final disk image.

An ssh key pair was generated for use during this lab, you can view the public part like this for later use. There's no newline at the end of this file, so the `echo` is just to make copying the output easier.
[source,bash,role="execute",subs=attributes+]
----
cat ~/.ssh/{guid}key.pub; echo
----
....
ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIAuXnpoluye+KM+9tvIAdHf+F0IHh+K73tlcjEG8LJRB
....
NOTE: This is only a sample and this public key will not work in your environment

You can now create a file called `config.toml` with the following contents, replacing "SSHKEY" 
in the `key` field with the contents of public key from your system.

[source,bash,role="execute",subs=attributes+]
----
nano config.toml
----

[source,yaml,role="execute",subs=attributes+]
----
[[customizations.user]]
name = "core"
password = "redhat"
groups = ["wheel"]
key = "SSHKEY"
----

This configuration blueprint creates a user in the wheel group with the login `core`, the password `redhat` and the ssh key of the user on the lab host.

[#create]
== Create the disk image

To create a bootable disk image from an OCI image, we have a special version of image builder that has support for `bootc`. This `bootc-image-builder` itself runs as a container, and as a result needs additional capabilities and to be run as `root`. 

As `bootc-image-builder` accesses local storage to find the source image, we need our image in system storage. 
If we'd built as a non-root user, the `podman image scp` command can do this for us, as well as copying to various different targets.


Try to generate the image now:

NOTE: This could take 2+ minutes to complete.

[source,bash,role="execute",subs=attributes+]
----
sudo podman run --rm --privileged --security-opt label=type:unconfined_t \
  --volume ./config.toml:/config.toml \
  --volume /var/lib/containers/storage:/var/lib/containers/storage \
  --volume .:/output \
  registry.redhat.io/rhel10/bootc-image-builder:10.1 \
  --type qcow2 \
  registry-{guid}.{domain}/base
----

A brief explanation of the arguments used for `podman run` and `bootc-image-builder`:

  * `--privileged` -> add capabilities required to build the image
  * `--volume` -> podman will map these local directories or files to the container to capture the config, load the bootc image, and store the results
  * `registry.redhat.io/rhel10/bootc-image-builder:10.1` -> the image builder container image

After the image builder version, these arguments passed to `bootc-image-builder`:

  * `--type qcow2` -> the type of image to build
  * `registry-{guid}.{domain}/base` -> the bootc image we are unpacking into the qcow2 disk

Once this completes, you will find the image in the `qcow2/` directory:

[source,bash,role="execute",subs=attributes+]
----
file qcow2/disk.qcow2
----
....
qcow2/disk.qcow2: QEMU QCOW2 Image (v3), 10737418240 bytes
....

[#create-vm]
== Create the virtual machine

Since we provided the QCOW2 type to `bootc-image-builder`, the resulting disk image is complete and ready to run without additional installation or other steps. We can copy the image to the standard storage pool location for KVM.

[source,bash,role="execute",subs=attributes+]
----
cp qcow2/disk.qcow2 /var/lib/libvirt/images/bootc-vm.qcow2
----

The creation of KVM virtual machines is out of scope for this lab, but the core of the `virt-install` command used is `--import` which skips any install process and creates the VM around the provided disk image. 

[source,bash,role="execute",subs=attributes+]
----
virt-install --name bootc-vm \
  --disk /var/lib/libvirt/images/bootc-vm.qcow2 \
  --import \
  --memory 4096 \
  --graphics none \
  --osinfo rhel10-unknown \
  --noautoconsole \
  --noreboot
----

We can now start our new bootc virtual machine.

[source,bash,role="execute",subs=attributes+]
----
virsh start bootc-vm
----

== Swith to the image mode VM
NOTE: The terminal pages for the KVM guests have a script that will wait for SSH to become available before trying to log in. If there's a problem with an SSH connection, you can restart the connection using the refresh button in the tab.

[#test]
== Test and login to the virtual machine
Click on the tab labeled "Ops VM" 

Once the script detects SSH is running, you should be automatically logged in as the `core` user created in the `bootc-image-builder` customization. 
Let's test one of the packages installed from `EPEL` during the build process.
[source,bash,role="execute",subs=attributes+]
----
btop
----
TIP: You can hit `q` to exit `btop`

Image mode hosts introduce a new way of understanding what's running on a host. 
The new `bootc` command is at the heart of operations on image mode hosts.
Let's familiarize ourselves with the `status` options first.

This status provides information about the images on the host. There are 3 different images that may be available on a bootc host: the booted image, the staged image, and the rollback image. We'll discuss the latter two images later in the lab. The booted image is what's currently defined as the active environment. The image name here is what `bootc` tracks to detect any updates that come available. 

TIP: The `sudo` password was set in the customization blueprint as `redhat`

[source,bash,role="execute",subs=attributes+]
----
sudo bootc status
----
....
Booted image: registry-pw6dg.apps.ocpvdev01.rhdp.net/base
        Digest: sha256:3d0fab2f019f5b641ccf3e41853f2e3b720a96aaa7a3d786548a47b3f098cc02 (amd64)
       Version: 10.1 (2025-11-19T17:11:53Z)
....

First, `bootc` tells you directly if it's being run on an image mode host or not. If `bootc` were to be installed and run on a non-bootc host, `bootc status` will show all `null` values instead of the output seen here. 
The core information shows is the image in use, the digest, and some version information.

More information is available with the `--verbose` flag.
[source,bash,role="execute",subs=attributes+]
----
sudo bootc status --verbose
----
....
Booted image: registry-pw6dg.apps.ocpvdev01.rhdp.net/base
        Digest: sha256:3d0fab2f019f5b641ccf3e41853f2e3b720a96aaa7a3d786548a47b3f098cc02 (amd64)
       Version: 10.1 (2025-11-19T17:11:53Z)
     StateRoot: default
 Deploy serial: 0
        Staged: no
        Commit: 564872a699359b7988e63851bc24b60da83072c0c150849c4ecd8f606c0aa487
   Soft-reboot: yes
....

Status doesn't stop there.
Full internal information about the images can be found by using the `--format` tag to ask for additional detail in YAML or JSON.
This can be useful for troubleshooting or for using this information in other tools.
[source,bash,role="execute",subs=attributes+]
----
sudo bootc status --format yaml
----
....
apiVersion: org.containers.bootc/v1
kind: BootcHost
metadata:
  name: host
spec:
  image:
    image: registry-pw6dg.apps.ocpvdev01.rhdp.net/base
    transport: registry
  bootOrder: default
status:
  staged: null
  booted:
    image:
      image:
        image: registry-pw6dg.apps.ocpvdev01.rhdp.net/base
        transport: registry
      version: '10.1'
      timestamp: 2025-11-19T17:11:53Z
      imageDigest: sha256:3d0fab2f019f5b641ccf3e41853f2e3b720a96aaa7a3d786548a47b3f098cc02
      architecture: amd64
    cachedUpdate:
      image:
        image: registry-pw6dg.apps.ocpvdev01.rhdp.net/base
        transport: registry
      version: '10.1'
      timestamp: 2025-11-19T17:11:53Z
      imageDigest: sha256:6d5958c5d8bb1e3ea0b46751d06600cf30078bf5ba6124f65a200794e3fefa32
      architecture: amd64
    incompatible: false
    pinned: false
    softRebootCapable: true
    store: ostreeContainer
    ostree:
      stateroot: default
      checksum: 564872a699359b7988e63851bc24b60da83072c0c150849c4ecd8f606c0aa487
      deploySerial: 0
  rollback: null
  rollbackQueued: false
  type: bootcHost
....




For other ways, we can look at how the system was started, let's look at kernel command line.

[source,bash,role="execute",subs=attributes+]
----
 cat /proc/cmdline
----
....
BOOT_IMAGE=(hd0,gpt3)/boot/ostree/default-8229ec6e3d87cd7730bff98dd2a6aeedb8727371cd61de8783c3fe8234bd2797/vmlinuz-6.12.0-124.8.1.el10_1.x86_64 root=UUID=37979fd9-1866-466d-8795-4c8c7594031c rw boot=UUID=5613f646-1ab4-49cd-862b-c0636c26af6a rw console=tty0 console=ttyS0 ostree=/ostree/boot.1/default/8229ec6e3d87cd7730bff98dd2a6aeedb8727371cd61de8783c3fe8234bd2797/0
....

We can see in the kernel command line some clear ties to an `ostree` partition, which is how images are stored and managed on a bootc host. We'll talk more about that later.

One other obvious difference for bootc hosts is the layout of the filesystem. 
Let's ignore the dynamic `/run` directories.

[source,bash,role="execute",subs=attributes+]
----
 df -Th | grep -v run
----
....
Filesystem     Type      Size  Used Avail Use% Mounted on
composefs      overlay   7.6M  7.6M     0 100% /
/dev/vda4      xfs       8.5G  2.3G  6.3G  27% /etc
devtmpfs       devtmpfs  1.9G     0  1.9G   0% /dev
tmpfs          tmpfs     2.0G     0  2.0G   0% /dev/shm
tmpfs          tmpfs     2.0G     0  2.0G   0% /tmp
/dev/vda3      xfs       960M  157M  804M  17% /boot
/dev/vda2      vfat      501M  8.8M  492M   2% /boot/efi
....

Rather than the usual layout, you'll notice that our root filesystem is an overlay and `/sysroot` looks like where most of the storage is used. You can also check the output of `ls -l /` and notice that there are a lot of symlinks where you might expect directories or filesystems.  This is a key difference that is tied to how updates, rollbacks, and software management works on image mode hosts.  We'll explore this in a later exercise.

[source,bash,role="execute",subs=attributes+]
----
systemctl status rsyslog.service
----
Before proceeding, make sure you have changed back to the builder terminal.

